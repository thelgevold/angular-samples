# the hash function for this worker, required
# to match out of band between the client and server
# since resource names must be determined on the client
# for a valid upload
hash_function: SHA256

# the endpoint used to execute operations
operation_queue: {
  target: "portland.home:8980"

  # the instance domain that this worker will execute work in
  # all requests will be tagged with this instance name
  instance_name: "default_memory_instance"
}

# the endpoint used for cas interactions
content_addressable_storage: {
  target: "portland.home:8980"

  # the instance domain that this worker will make resource requests in
  # all requests will be tagged with this instance name
  instance_name: "default_memory_instance"
}

# the endpoint used for action cache interactions
action_cache: {
  target: "portland.home:8980"

  # the instance domain that this worker will make resource requests in
  # all requests will be tagged with this instance name
  instance_name: "default_memory_instance"
}

# all content for the operations will be stored under this path
root: "/tmp/worker"

# the local cache location relative to the 'root', or absolute
cas_cache_directory: "cache"

# total size in bytes of inline content for action results
# output files, stdout, and stderr content, in that order
# will be inlined if their cumulative size does not exceed this limit.
inline_content_limit: 1048567 # 1024 * 1024

# whether the stdout of running processes should be streamed
stream_stdout: true

# whether to insert stdout into the CAS, can be:
#   ALWAYS_INSERT: stdout is always inserted into the CAS
#   INSERT_ABOVE_LIMIT: stdout is inserted into the CAS when it exceeds the inline limit above
stdout_cas_policy: ALWAYS_INSERT

# whether the stderr of running processes should be streamed
stream_stderr: true

# whether to insert stderr into the CAS, can be:
#   ALWAYS_INSERT: stderr is always inserted into the CAS
#   INSERT_ABOVE_LIMIT: stderr is inserted into the CAS when it exceeds the inline limit above
stderr_cas_policy: ALWAYS_INSERT

# whether to insert output files into the CAS, can be:
#   ALWAYS_INSERT: output files are always inserted into the CAS
#   INSERT_ABOVE_LIMIT: output files are inserted into the CAS when it exceeds the inline limit above
file_cas_policy: ALWAYS_INSERT

# the worker will take it upon itself to requeue (exceptionally)
# failed operations via the OperationQueue#put method with queued
# status.
requeue_on_failure: true

# ContentAddressableStorage#getTree per-page directory count
# value of '0' means let the server decide
tree_page_size: 0

# the period between poll operations at any stage
operation_poll_period: {
  seconds: 1
  nanos: 0
}

# key/value set of definining capabilities of this worker
# all execute requests must match perfectly with workers which
# provide capabilities
# so an action with a required platform: { arch: "x86_64" } must
# match with a worker with at least { arch: "x86_64" } here
platform: {
  # commented out here for illustrative purposes, a default empty
  # 'platform' is a sufficient starting point without specifying
  # any platform requirements on the actions' side
  ###
  # property: {
  #   name: "key_name"
  #   value: "value_string"
  # }
}

# limit for contents of files retained
# from CAS in the cache
cas_cache_max_size_bytes: 2147483648 # 2 * 1024 * 1024 * 1024

# the number of concurrently available slots in the execute phase
execute_stage_width: 10

# an imposed action-key-invariant timeout used in the unspecified timeout case
default_action_timeout: {
  seconds: 600
  nanos: 0
}

# a limit on the action timeout specified in the action, above which
# the operation will report a failed result immediately
maximum_action_timeout: {
  seconds: 3600
  nanos: 0
}